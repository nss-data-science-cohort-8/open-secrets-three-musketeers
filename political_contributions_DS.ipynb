{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27a3ca58-89fe-4fe4-99b4-b5213b664958",
   "metadata": {},
   "source": [
    "# An Analysis of Political Contributions During the 2020 House of Representatives Election\r\n",
    "\r\n",
    "In this part, you will obtain as much data as you can on the campaign contributions received by each candidate. This data is avaiable through the website https://www.opensecrets.org/.\r\n",
    "\r\n",
    "### Part 1: Data Gathering\r\n",
    "1. Start by acquiring the data from Tennessee's 7th District, which is available at https://www.opensecrets.org/races/summary?cycle=2020&id=TN07&spec=N. If you click the \"Download .csv file\", you can get a csv for this district. However, we don't want to have to click this button across all districts. Instead, we'll use Python to help automate this process. Start by sending a get request to the download button URL, https://www.opensecrets.org/races/summary.csv?cycle=2020&id=TN07. Convert the result to a DataFrame.\r\n",
    "2. Once you have working code for Tennessee's 7th District, expand on your code to capture all of Tennessee's districts into a single DataFrame. Make sure that you can distinguish which district each result came from. Export the results to a csv file.\r\n",
    "3. Once you have working code for all of Tennessee's districts, expand on it to capture all states and districts. The number of districts for each state can be found at https://en.wikipedia.org/wiki/2020_United_States_House_of_Representatives_elections. You may also find the table of state abbreviations here helpful: https://en.wikipedia.org/wiki/List_of_U.S._state_and_territory_abbreviations. Export a csv file for each state.\r\n",
    "4. Finally, combine all of the data you've gathered together into a single DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4511c6b-121f-4f66-85d3-ee7ee0b78f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\vetdd\\anaconda3\\lib\\site-packages (4.12.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\vetdd\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.5)\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "!pip install beautifulsoup4\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.core.display import HTML\n",
    "import pandas as pd\n",
    "import io\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "945c1ad8-8e56-4cfd-8fa5-6fa67158ed0f",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4139869414.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[23], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    https://www.opensecrets.org/races/summary?cycle=2020&id=TN01&spec=N\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "URL ='https://www.opensecrets.org/races/summary.csv?cycle=2020&id=TN07'\n",
    "https://www.opensecrets.org/races/summary?cycle=2020&id=TN01&spec=N\n",
    "response = requests.get(URL)\n",
    "soup = BeautifulSoup(response.text, features=\"html.parser\")\n",
    "csv_file = io.StringIO(soup.prettify())\n",
    "ten_d7 = pd.read_csv(csv_file)\n",
    "print(ten_d7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0a1a61f-6605-47c7-8560-121eaa8cff7b",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1932418828.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[21], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    https://www.opensecrets.org/races/summary?cycle=2020&id=TN01&spec=N\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "URL = 'https://www.opensecrets.org/races/summary.csv?cycle=2020&id=TN07'\n",
    "https://www.opensecrets.org/races/summary?cycle=2020&id=TN01&spec=N\n",
    "response = requests.get(URL)\n",
    "soup = BeautifulSoup(response.text, features=\"html.parser\")\n",
    "csv_file = io.StringIO(soup.prettify())\n",
    "ten_d7 = pd.read_csv(csv_file)\n",
    "print(ten_d7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "920117cc-c947-446e-a992-123cfb147169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.opensecrets.org/races/summary.csv?cycle=2020&id=TN01\n",
      "https://www.opensecrets.org/races/summary.csv?cycle=2020&id=TN02\n",
      "https://www.opensecrets.org/races/summary.csv?cycle=2020&id=TN03\n",
      "https://www.opensecrets.org/races/summary.csv?cycle=2020&id=TN04\n",
      "https://www.opensecrets.org/races/summary.csv?cycle=2020&id=TN05\n",
      "https://www.opensecrets.org/races/summary.csv?cycle=2020&id=TN06\n",
      "https://www.opensecrets.org/races/summary.csv?cycle=2020&id=TN07\n",
      "https://www.opensecrets.org/races/summary.csv?cycle=2020&id=TN08\n",
      "https://www.opensecrets.org/races/summary.csv?cycle=2020&id=TN09\n"
     ]
    }
   ],
   "source": [
    "# Original URL string\n",
    "original_url = \"https://www.opensecrets.org/races/summary?cycle=2020&id=TN07&spec=N\"\n",
    "\n",
    "# Convert to the desired URL\n",
    "# Replace 'summary' with 'summary.csv' and remove the '&spec=N' part\n",
    "new_url = original_url.replace(\"summary\", \"summary.csv\").split(\"&spec=\")[0]\n",
    "\n",
    "# List to hold the new URLs\n",
    "new_urls = []\n",
    "\n",
    "# Loop through district IDs from TN01 to TN09\n",
    "for i in range(1, 10):\n",
    "    district_id = f'TN{i:02d}'  # Format to ensure two digits (TN01, TN02, ..., TN09)\n",
    "    new_url2 = new_url.replace(\"TN07\", district_id)  # Replace TN07 with the new district ID\n",
    "    new_urls.append(new_url2)  # Add the new URL to the list\n",
    "\n",
    "# Print the new URLs\n",
    "for url in new_urls:\n",
    "    print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac8e578-14ef-4761-80bc-16eedc051748",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import csv\n",
    "\n",
    "# List of all TN district URLs to fetch data from\n",
    "urls = [\n",
    "    \"https://www.opensecrets.org/races/summary.csv?cycle=2020&id=TN01\",\n",
    "    \"https://www.opensecrets.org/races/summary.csv?cycle=2020&id=TN02\",\n",
    "    \"https://www.opensecrets.org/races/summary.csv?cycle=2020&id=TN03\",\n",
    "    \"https://www.opensecrets.org/races/summary.csv?cycle=2020&id=TN04\",\n",
    "    \"https://www.opensecrets.org/races/summary.csv?cycle=2020&id=TN05\",\n",
    "    \"https://www.opensecrets.org/races/summary.csv?cycle=2020&id=TN06\",\n",
    "    \"https://www.opensecrets.org/races/summary.csv?cycle=2020&id=TN07\",\n",
    "    \"https://www.opensecrets.org/races/summary.csv?cycle=2020&id=TN08\",\n",
    "    \"https://www.opensecrets.org/races/summary.csv?cycle=2020&id=TN09\"\n",
    "]\n",
    "\n",
    "# Specify the output CSV filename\n",
    "output_filename = 'combined_data.csv'\n",
    "\n",
    "# Create a list to store all rows\n",
    "all_rows = []\n",
    "\n",
    "# Get data from each URL\n",
    "for url in urls:\n",
    "    try:\n",
    "        # Send a GET request to obtain the CSV data\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # will raise an error for bad responses\n",
    "\n",
    "        # get text of the content and split into lines\n",
    "        csv_data = response.text.splitlines()\n",
    "        \n",
    "        # Read the CSV data\n",
    "        reader = csv.reader(csv_data)\n",
    "        # If the first URL contains a header, use it\n",
    "        if not all_rows:\n",
    "            header = next(reader)  # Get the header row\n",
    "            all_rows.append(header)  # Append the header to the list\n",
    "        \n",
    "        # Append the rest of the rows from the current CSV\n",
    "        for row in reader:\n",
    "            all_rows.append(row)\n",
    "                                  \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching data from {url}: {e}\")\n",
    "    # Write the new  header and all combined data to a single CSV file\n",
    "with open(output_filename, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(all_rows)  # Write all combined rows\n",
    "\n",
    "#create a dataframe from 'combined_data.csv'\n",
    "ten_all = pd.read_csv('combined_data.csv')\n",
    "\n",
    "#cleaning ten_all dataframe\n",
    "# Remove duplicate header rows and keep only the first occurence of the header\n",
    "header = ten_all.columns.tolist()\n",
    "ten_all_cleaned = ten_all[~ten_all.apply(lambda row: row.tolist() == header, axis=1)]\n",
    "ten_all_cleaned.reset_index(drop=True, inplace=True) # Reset index after removing duplicates\n",
    "#add district ID into empty space in column 'DistIDCurr' using .replace to get Na in all no value space and use forward fill to put value of the first scanned rows of the column into the next row with Na value\n",
    "ten_all_cleaned.loc[0, 'DistIDCurr'] = 'TN01'\n",
    "ten_all_cleaned['DistIDCurr'] = ten_all_cleaned['DistIDCurr'].replace(r'^\\s*$', None, regex=True)\n",
    "ten_all_cleaned['DistIDCurr'] = ten_all_cleaned['DistIDCurr'].fillna(method='ffill')\n",
    "\n",
    "#Convert DataFrame to CSV\n",
    "ten_all_cleaned.to_csv('ten_all.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3756fa85-e23d-46bd-bad0-8c732c0388f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        State_name  Total_seat\n",
      "0          Alabama           7\n",
      "1           Alaska           1\n",
      "2          Arizona           9\n",
      "3         Arkansas           4\n",
      "4       California          53\n",
      "5         Colorado           7\n",
      "6      Connecticut           5\n",
      "7         Delaware           1\n",
      "8          Florida          27\n",
      "9          Georgia          14\n",
      "10          Hawaii           2\n",
      "11           Idaho           2\n",
      "12        Illinois          18\n",
      "13         Indiana           9\n",
      "14            Iowa           4\n",
      "15          Kansas           4\n",
      "16        Kentucky           6\n",
      "17       Louisiana           6\n",
      "18           Maine           2\n",
      "19        Maryland           8\n",
      "20   Massachusetts           9\n",
      "21        Michigan          14\n",
      "22       Minnesota           8\n",
      "23     Mississippi           4\n",
      "24        Missouri           8\n",
      "25         Montana           1\n",
      "26        Nebraska           3\n",
      "27          Nevada           4\n",
      "28   New Hampshire           2\n",
      "29      New Jersey          12\n",
      "30      New Mexico           3\n",
      "31        New York          27\n",
      "32  North Carolina          13\n",
      "33    North Dakota           1\n",
      "34            Ohio          16\n",
      "35        Oklahoma           5\n",
      "36          Oregon           5\n",
      "37    Pennsylvania          18\n",
      "38    Rhode Island           2\n",
      "39  South Carolina           7\n",
      "40    South Dakota           1\n",
      "41       Tennessee           9\n",
      "42           Texas          36\n",
      "43            Utah           4\n",
      "44         Vermont           1\n",
      "45        Virginia          11\n",
      "46      Washington          10\n",
      "47   West Virginia           3\n",
      "48       Wisconsin           8\n",
      "49         Wyoming           1\n",
      "50           Total         435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vetdd\\AppData\\Local\\Temp\\ipykernel_29144\\2360039545.py:16: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  total_seat_df = pd.read_html(str(second_table))[0]\n"
     ]
    }
   ],
   "source": [
    "# URL of the Wikipedia page\n",
    "url = 'https://en.wikipedia.org/wiki/2020_United_States_House_of_Representatives_elections'\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    # Find the table that contains state names and seat numbers\n",
    "    tables = soup.find_all('table')\n",
    "    if len(tables) >= 2:\n",
    "        second_table = tables[6]\n",
    "        total_seat_df = pd.read_html(str(second_table))[0]\n",
    "        #print(total_seat_df)\n",
    "        \n",
    "    # drop other columns\n",
    "        total_seat = total_seat_df.iloc[:, [0, 1]]\n",
    "        total_seat.columns = [\"State_name\", \"Total_seat\"]\n",
    "        print(total_seat)\n",
    "        \n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d8ee55ed-75a2-4180-9739-31ccf11543fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                State_name State_Abbr\n",
      "0                 United States of America        NaN\n",
      "1                                  Alabama         AL\n",
      "2                                   Alaska         AK\n",
      "3                                  Arizona         AZ\n",
      "4                                 Arkansas         AR\n",
      "..                                     ...        ...\n",
      "73                                Nebraska         NB\n",
      "74                Northern Mariana Islands         CM\n",
      "75                       Panama Canal Zone         CZ\n",
      "76                      Philippine Islands         PI\n",
      "77  Trust Territory of the Pacific Islands         TT\n",
      "\n",
      "[78 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vetdd\\AppData\\Local\\Temp\\ipykernel_29144\\2269149431.py:16: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  state_abb_df = pd.read_html(str(second_table))[0]\n"
     ]
    }
   ],
   "source": [
    "# URL of the Wikipedia page for state abbre\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_U.S._state_and_territory_abbreviations'\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    # Find the table that contains state names and seat numbers\n",
    "    tables = soup.find_all('table')\n",
    "    if len(tables) >= 2:\n",
    "        second_table = tables[1]\n",
    "        state_abb_df = pd.read_html(str(second_table))[0]\n",
    "    # drop other columns\n",
    "        state_abb = state_abb_df.iloc[:, [0, 5]]\n",
    "        state_abb.columns = [\"State_name\", \"State_Abbr\"]\n",
    "        print(state_abb)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d6e68d14-2c1a-49be-91ef-103400646f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        State_name State_Abbr  Total_seat\n",
      "0          Alabama         AL           7\n",
      "1           Alaska         AK           1\n",
      "2          Arizona         AZ           9\n",
      "3         Arkansas         AR           4\n",
      "4       California         CA          53\n",
      "5         Colorado         CO           7\n",
      "6      Connecticut         CT           5\n",
      "7         Delaware         DE           1\n",
      "8          Florida         FL          27\n",
      "9          Georgia         GA          14\n",
      "10          Hawaii         HI           2\n",
      "11           Idaho         ID           2\n",
      "12        Illinois         IL          18\n",
      "13         Indiana         IN           9\n",
      "14            Iowa         IA           4\n",
      "15          Kansas         KS           4\n",
      "16        Kentucky         KY           6\n",
      "17       Louisiana         LA           6\n",
      "18           Maine         ME           2\n",
      "19        Maryland         MD           8\n",
      "20   Massachusetts         MA           9\n",
      "21        Michigan         MI          14\n",
      "22       Minnesota         MN           8\n",
      "23     Mississippi         MS           4\n",
      "24        Missouri         MO           8\n",
      "25         Montana         MT           1\n",
      "26        Nebraska         NE           3\n",
      "27          Nevada         NV           4\n",
      "28   New Hampshire         NH           2\n",
      "29      New Jersey         NJ          12\n",
      "30      New Mexico         NM           3\n",
      "31        New York         NY          27\n",
      "32  North Carolina         NC          13\n",
      "33    North Dakota         ND           1\n",
      "34            Ohio         OH          16\n",
      "35        Oklahoma         OK           5\n",
      "36          Oregon         OR           5\n",
      "37    Pennsylvania         PA          18\n",
      "38    Rhode Island         RI           2\n",
      "39  South Carolina         SC           7\n",
      "40    South Dakota         SD           1\n",
      "41       Tennessee         TN           9\n",
      "42           Texas         TX          36\n",
      "43            Utah         UT           4\n",
      "44         Vermont         VT           1\n",
      "45        Virginia         VA          11\n",
      "46      Washington         WA          10\n",
      "47   West Virginia         WV           3\n",
      "48       Wisconsin         WI           8\n",
      "49         Wyoming         WY           1\n",
      "50        Nebraska         NB           3\n"
     ]
    }
   ],
   "source": [
    "#merge state abb with seat number\n",
    "US_state_seat_Abb = pd.merge(state_abb, total_seat, on =\"State_name\",how=\"inner\")\n",
    "print(US_state_seat_Abb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e3723262-555f-4a26-8797-abfe703c46ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        State_name State_Abbr  Total_seat  \\\n",
      "0          Alabama         AL           7   \n",
      "1           Alaska         AK           1   \n",
      "2          Arizona         AZ           9   \n",
      "3         Arkansas         AR           4   \n",
      "4       California         CA          53   \n",
      "5         Colorado         CO           7   \n",
      "6      Connecticut         CT           5   \n",
      "7         Delaware         DE           1   \n",
      "8          Florida         FL          27   \n",
      "9          Georgia         GA          14   \n",
      "10          Hawaii         HI           2   \n",
      "11           Idaho         ID           2   \n",
      "12        Illinois         IL          18   \n",
      "13         Indiana         IN           9   \n",
      "14            Iowa         IA           4   \n",
      "15          Kansas         KS           4   \n",
      "16        Kentucky         KY           6   \n",
      "17       Louisiana         LA           6   \n",
      "18           Maine         ME           2   \n",
      "19        Maryland         MD           8   \n",
      "20   Massachusetts         MA           9   \n",
      "21        Michigan         MI          14   \n",
      "22       Minnesota         MN           8   \n",
      "23     Mississippi         MS           4   \n",
      "24        Missouri         MO           8   \n",
      "25         Montana         MT           1   \n",
      "26        Nebraska         NE           3   \n",
      "27          Nevada         NV           4   \n",
      "28   New Hampshire         NH           2   \n",
      "29      New Jersey         NJ          12   \n",
      "30      New Mexico         NM           3   \n",
      "31        New York         NY          27   \n",
      "32  North Carolina         NC          13   \n",
      "33    North Dakota         ND           1   \n",
      "34            Ohio         OH          16   \n",
      "35        Oklahoma         OK           5   \n",
      "36          Oregon         OR           5   \n",
      "37    Pennsylvania         PA          18   \n",
      "38    Rhode Island         RI           2   \n",
      "39  South Carolina         SC           7   \n",
      "40    South Dakota         SD           1   \n",
      "41       Tennessee         TN           9   \n",
      "42           Texas         TX          36   \n",
      "43            Utah         UT           4   \n",
      "44         Vermont         VT           1   \n",
      "45        Virginia         VA          11   \n",
      "46      Washington         WA          10   \n",
      "47   West Virginia         WV           3   \n",
      "48       Wisconsin         WI           8   \n",
      "49         Wyoming         WY           1   \n",
      "50        Nebraska         NB           3   \n",
      "\n",
      "                                                 urls  \n",
      "0   https://www.opensecrets.org/races/summary?cycl...  \n",
      "1   https://www.opensecrets.org/races/summary?cycl...  \n",
      "2   https://www.opensecrets.org/races/summary?cycl...  \n",
      "3   https://www.opensecrets.org/races/summary?cycl...  \n",
      "4   https://www.opensecrets.org/races/summary?cycl...  \n",
      "5   https://www.opensecrets.org/races/summary?cycl...  \n",
      "6   https://www.opensecrets.org/races/summary?cycl...  \n",
      "7   https://www.opensecrets.org/races/summary?cycl...  \n",
      "8   https://www.opensecrets.org/races/summary?cycl...  \n",
      "9   https://www.opensecrets.org/races/summary?cycl...  \n",
      "10  https://www.opensecrets.org/races/summary?cycl...  \n",
      "11  https://www.opensecrets.org/races/summary?cycl...  \n",
      "12  https://www.opensecrets.org/races/summary?cycl...  \n",
      "13  https://www.opensecrets.org/races/summary?cycl...  \n",
      "14  https://www.opensecrets.org/races/summary?cycl...  \n",
      "15  https://www.opensecrets.org/races/summary?cycl...  \n",
      "16  https://www.opensecrets.org/races/summary?cycl...  \n",
      "17  https://www.opensecrets.org/races/summary?cycl...  \n",
      "18  https://www.opensecrets.org/races/summary?cycl...  \n",
      "19  https://www.opensecrets.org/races/summary?cycl...  \n",
      "20  https://www.opensecrets.org/races/summary?cycl...  \n",
      "21  https://www.opensecrets.org/races/summary?cycl...  \n",
      "22  https://www.opensecrets.org/races/summary?cycl...  \n",
      "23  https://www.opensecrets.org/races/summary?cycl...  \n",
      "24  https://www.opensecrets.org/races/summary?cycl...  \n",
      "25  https://www.opensecrets.org/races/summary?cycl...  \n",
      "26  https://www.opensecrets.org/races/summary?cycl...  \n",
      "27  https://www.opensecrets.org/races/summary?cycl...  \n",
      "28  https://www.opensecrets.org/races/summary?cycl...  \n",
      "29  https://www.opensecrets.org/races/summary?cycl...  \n",
      "30  https://www.opensecrets.org/races/summary?cycl...  \n",
      "31  https://www.opensecrets.org/races/summary?cycl...  \n",
      "32  https://www.opensecrets.org/races/summary?cycl...  \n",
      "33  https://www.opensecrets.org/races/summary?cycl...  \n",
      "34  https://www.opensecrets.org/races/summary?cycl...  \n",
      "35  https://www.opensecrets.org/races/summary?cycl...  \n",
      "36  https://www.opensecrets.org/races/summary?cycl...  \n",
      "37  https://www.opensecrets.org/races/summary?cycl...  \n",
      "38  https://www.opensecrets.org/races/summary?cycl...  \n",
      "39  https://www.opensecrets.org/races/summary?cycl...  \n",
      "40  https://www.opensecrets.org/races/summary?cycl...  \n",
      "41  https://www.opensecrets.org/races/summary?cycl...  \n",
      "42  https://www.opensecrets.org/races/summary?cycl...  \n",
      "43  https://www.opensecrets.org/races/summary?cycl...  \n",
      "44  https://www.opensecrets.org/races/summary?cycl...  \n",
      "45  https://www.opensecrets.org/races/summary?cycl...  \n",
      "46  https://www.opensecrets.org/races/summary?cycl...  \n",
      "47  https://www.opensecrets.org/races/summary?cycl...  \n",
      "48  https://www.opensecrets.org/races/summary?cycl...  \n",
      "49  https://www.opensecrets.org/races/summary?cycl...  \n",
      "50  https://www.opensecrets.org/races/summary?cycl...  \n"
     ]
    }
   ],
   "source": [
    "# list of state abb\n",
    "state_abb_list = US_state_seat_Abb.iloc[:, [1]]\n",
    "Base_url =  'https://www.opensecrets.org/races/summary?cycle=2020&id=AL01&spec=N'\n",
    "new_urls = []\n",
    "\n",
    "for state_abbr in state_abb_list['State_Abbr']:\n",
    "    new_url = Base_url.replace('AL', state_abbr)\n",
    "    new_urls.append(new_url)\n",
    "\n",
    "#add column to the US_state_seat_Abb\n",
    "US_state_seat_Abb['urls'] = new_urls\n",
    "print(US_state_seat_Abb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "79d7f0eb-d245-40b1-888d-eb7f7ff4bd70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted URL: https://www.opensecrets.org/races/summary.csv?cycle=2020&id=AL01\n",
      "https://www.opensecrets.org/races/summary.csv?cycle=2020&id=AL01\n",
      "https://www.opensecrets.org/races/summary.csv?cycle=2020&id=AL02\n",
      "https://www.opensecrets.org/races/summary.csv?cycle=2020&id=AL03\n",
      "https://www.opensecrets.org/races/summary.csv?cycle=2020&id=AL04\n",
      "https://www.opensecrets.org/races/summary.csv?cycle=2020&id=AL05\n",
      "https://www.opensecrets.org/races/summary.csv?cycle=2020&id=AL06\n",
      "https://www.opensecrets.org/races/summary.csv?cycle=2020&id=AL07\n",
      "https://www.opensecrets.org/races/summary.csv?cycle=2020&id=AL08\n",
      "https://www.opensecrets.org/races/summary.csv?cycle=2020&id=AL09\n"
     ]
    }
   ],
   "source": [
    "#get list of url csv districts from AL\n",
    "# Original URL string\n",
    "original_url = \"https://www.opensecrets.org/races/summary?cycle=2020&id=AL01&spec=N\"\n",
    "\n",
    "# Convert to the desired URL\n",
    "\n",
    "new_url = original_url.replace(\"summary\", \"summary.csv\").split(\"&spec=\")[0]\n",
    "\n",
    "# Print the converted URL\n",
    "print(\"Converted URL:\", new_url)\n",
    "\n",
    "# List to hold the new URLs\n",
    "new_urls = []\n",
    "\n",
    "# Loop through district IDs from TN01 to TN09\n",
    "for i in range(1, 10):\n",
    "    district_id = f'AL{i:02d}'  \n",
    "    new_url2 = new_url.replace(\"AL01\", district_id)  \n",
    "    new_urls.append(new_url2)  \n",
    "\n",
    "# Print the new URLs\n",
    "for url in new_urls:\n",
    "    print(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed48cc8-91b6-49d2-8bc4-045e064782be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a DataFrame with 'politic' and 'district_count' columns\n",
    "data = US_state_seat_Abb\n",
    "original_url = \"https://www.opensecrets.org/races/summary?cycle=2020&id=AL01&spec=N\"  \n",
    "# Function to generate URLs\n",
    "def generate_urls(original_url, US_state_seat_Abb[\"urls\"], US_state_seat_Abb[\"Total_seat\"]):\n",
    "    # Convert the original URL to the desired format\n",
    "    new_url = original_url.replace(\"summary\", \"summary.csv\").split(\"&spec=\")[0]\n",
    "    \n",
    "    # List to hold the new URLs\n",
    "    new_urls = []\n",
    "    \n",
    "    # Loop through the district numbers\n",
    "    for i in range(1, US_state_seat_Abb[\"Total_seat\"] + 1):\n",
    "        district_id = f'{state_abbr}{i:02d}'  # Format to ensure two digits\n",
    "        new_url2 = new_url.replace(\"AL01\", district_id)  # Replace 'AL01' with the new district ID\n",
    "        new_urls.append(new_url2)  # Add the new URL to the list\n",
    "    \n",
    "    return new_urls\n",
    "\n",
    "# Original URL string\n",
    "original_url = \"https://www.opensecrets.org/races/summary?cycle=2020&id=AL01&spec=N\"\n",
    "\n",
    "# Generate URLs for each row in the DataFrame\n",
    "all_new_urls = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    state_abbr = row['politic']  # Get state abbreviation\n",
    "    district_count = row['district_count']  # Get number of districts\n",
    "    urls = generate_urls(original_url, state_abbr, district_count)\n",
    "    all_new_urls.extend(urls)  # Add to the final list of URLs\n",
    "\n",
    "# Print all the new URLs\n",
    "for url in all_new_urls:\n",
    "    print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384eac04-2af7-41f2-b641-f99de752798d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
